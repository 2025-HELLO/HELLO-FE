import { useEffect, useRef, useState } from 'react';
import type { KeyboardEventHandler, MouseEvent } from 'react';
import * as s from './Chat.css';

/** ===== Web Speech ìµœì†Œ íƒ€ì… ì„ ì–¸ ===== */
type SpeechRecognitionResultLike = { 0: { transcript: string } };
type SpeechRecognitionEventLike = {
  resultIndex: number;
  results: ArrayLike<SpeechRecognitionResultLike>;
};
interface ISpeechRecognition {
  lang: string;
  continuous: boolean;
  interimResults: boolean;
  start: () => void;
  stop: () => void;
  abort: () => void;
  onstart?: () => void;
  onend?: () => void;
  onerror?: (e: unknown) => void;
  onresult?: (e: SpeechRecognitionEventLike) => void;
}
interface SpeechRecognitionConstructor {
  new (): ISpeechRecognition;
}
declare global {
  interface Window {
    webkitSpeechRecognition?: SpeechRecognitionConstructor;
    SpeechRecognition?: SpeechRecognitionConstructor;
  }
}

type Msg = {
  id: string;
  text: string;
  who: 'me' | 'other'; // me=ì‚¬ìš©ì(ì˜¤ë¥¸ìª½), other=AI(ì™¼ìª½)
  date?: string;
  audioSrc?: string; // ì‹œì—°ìš© mp3 ê²½ë¡œ
};

/** ================== ì´ˆê¸°: ìƒëŒ€ê°€ ë¨¼ì € ================== */
const initial: Msg[] = [
  { id: 'd1', text: '', who: 'other', date: '7ì›” 8ì¼ (í™”)' },
  {
    id: 'o0',
    who: 'other',
    text:
      'ì±„íŒ…ì„ ê¸¸ê²Œ í´ë¦­í•˜ë©´ ì„¤ì •í•œ ëª©ì†Œë¦¬ë¡œ ë‹µë³€ì„ ë“¤ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n' +
      'ì˜¤ëŠ˜ í•˜ë£¨ ì–´ë– ì…¨ì–´ìš”? ì²œì²œíˆ í¸í•˜ê²Œ ë§ì”€í•´ ì£¼ì„¸ìš”. ğŸ˜Š',
    audioSrc: '/audios/ai_intro.mp3',
  },
];

const Chat = () => {
  const [msgs, setMsgs] = useState<Msg[]>(initial);
  const [text, setText] = useState('');
  const [listening, setListening] = useState(false);

  const listRef = useRef<HTMLDivElement>(null);
  const recognitionRef = useRef<ISpeechRecognition | null>(null);

  // ì‹œì—°ìš©: ê¸¸ê²Œ ëˆ„ë¥´ë©´ mp3 ì¬ìƒ
  const pressTimerRef = useRef<number | null>(null);
  const audioRef = useRef<HTMLAudioElement | null>(null);

  // âœ… ê³ ì • ì‹œë‚˜ë¦¬ì˜¤ ì§„í–‰ ë‹¨ê³„ (0â†’1â†’2)
  const stepRef = useRef<number>(0);

  const newId = () => (crypto as any).randomUUID?.() ?? String(Date.now() + Math.random());

  // ìƒˆ ë©”ì‹œì§€ ìƒê¸¸ ë•Œ í•˜ë‹¨ ìŠ¤í¬ë¡¤
  useEffect(() => {
    const el = listRef.current;
    if (el) {
      el.scrollTop = el.scrollHeight;
    }
  }, [msgs.length]);

  // ì–¸ë§ˆìš´íŠ¸ ì •ë¦¬
  useEffect(() => {
    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
      if (audioRef.current) {
        audioRef.current.pause();
        audioRef.current.currentTime = 0;
      }
    };
  }, []);

  /** ============== ê³ ì • ì‹œë‚˜ë¦¬ì˜¤ ê·œì¹™ ==============
   * Step 0 (ë„¤ 1ë²ˆì§¸ ì…ë ¥):
   *  - ì‚¬ìš©ìê°€: "í–‡ì‚´" & "ë´‰ì˜¤ë¦¬/ê½ƒ" ëŠë‚Œ â†’ ë‹µ: "ì™€, ë²Œì¨ ê½ƒë´‰ì˜¤ë¦¬ê°€ ë³´ì˜€êµ°ìš”. ì–´ë–¤ ê½ƒì´ ì œì¼ ì˜ˆë»¤ë‚˜ìš”? ğŸŒ¸"
   *
   * Step 1 (ë„¤ 2ë²ˆì§¸ ì…ë ¥):
   *  - ì‚¬ìš©ìê°€: "ìˆ˜ì„ í™”" ë˜ëŠ” "ë“¤ê½ƒ/ë´„ì— ì•„ì´ë“¤ì´ë‘" ëŠë‚Œ â†’ ë‹µ: "ê·¸ë•Œ ì´ì•¼ê¸°ë„ ë” í•´ ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”? ë“£ê³  ì‹¶ì–´ìš”."
   *
   * Step 2 (ë„¤ 3ë²ˆì§¸ ì…ë ¥):
   *  - ì‚¬ìš©ìê°€: "ë‚´ì¼", "9ì‹œ", "íˆ¬ì¸(í”Œë ˆì´ìŠ¤)" â†’ ë‹µ: "íˆ¬ì¸ í”Œë ˆì´ìŠ¤ì—ì„œ ì¹œêµ¬ë“¤ê³¼ ì¢‹ì€ ì‹œê°„ ë³´ë‚´ì„¸ìš”! ì¼ì •ìœ¼ë¡œ ì €ì¥í• ê²Œìš”."
   *
   * â€» í‚¤ì›Œë“œë§Œ ë§ìœ¼ë©´ ë˜ê²Œ regex ì™„í™”. ìˆœì„œ/ë„ì–´ì“°ê¸°/ì¡°ì‚¬ ë‹¬ë¼ë„ ì¡í˜.
   */
  const SCRIPT = [
    {
      match: (t: string) => /í–‡ì‚´/.test(t) && /(ë´‰ì˜¤ë¦¬|ê½ƒ)/.test(t),
      reply: 'ì™€, ë²Œì¨ ê½ƒë´‰ì˜¤ë¦¬ê°€ ë³´ì˜€êµ°ìš”. ì–´ë–¤ ê½ƒì´ ì œì¼ ì˜ˆë»¤ë‚˜ìš”? ğŸŒ¸',
      audio: '/audios/ai_flow1.mp3',
    },
    {
      match: (t: string) => /(ìˆ˜ì„ í™”|ë“¤ê½ƒ)/.test(t) || (/ë´„/.test(t) && /(ì•„ì´|ì•„ì´ë“¤)/.test(t)),
      reply: 'ê·¸ë•Œ ì´ì•¼ê¸°ë„ ë” í•´ ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”? ë“£ê³  ì‹¶ì–´ìš”.',
      audio: '/audios/ai_flow2.mp3',
    },
    {
      match: (t: string) =>
        /(ë‚´ì¼)/.test(t) && /(9\s*ì‹œ)/.test(t) && /(íˆ¬\s*ì¸|íˆ¬ì¸\s*í”Œë ˆì´ìŠ¤|twosome)/i.test(t),
      reply: 'íˆ¬ì¸ í”Œë ˆì´ìŠ¤ì—ì„œ ì¹œêµ¬ë“¤ê³¼ ì¢‹ì€ ì‹œê°„ ë³´ë‚´ì„¸ìš”! ì¼ì •ìœ¼ë¡œ ì €ì¥í• ê²Œìš”.',
      audio: '/audios/ai_schedule.mp3',
    },
  ] as const;

  /** ============== ê³ ì • ì‹œë‚˜ë¦¬ì˜¤ ë‹µë³€ê¸° ============== */
  const makeFixedReply = (userText: string): { text: string; audio: string } => {
    const t = userText.replace(/\s+/g, ' ').trim();
    const i = Math.max(0, Math.min(stepRef.current, SCRIPT.length - 1));
    const node = SCRIPT[i];

    // í•´ë‹¹ ìŠ¤í…ì˜ íŒ¨í„´ì´ ë§ìœ¼ë©´ ê·¸ ë‹µë³€, ì•„ë‹ˆë©´ "ê°€ì¥ ê·¼ì ‘í•œ" ê·œì¹™ ìˆœíšŒë¡œ ë³´ì •
    if (node.match(t)) {
      stepRef.current = Math.min(stepRef.current + 1, SCRIPT.length - 1);
      return { text: node.reply, audio: node.audio };
    }

    // ë³´ì •(ì‚¬ìš©ìê°€ ì‚´ì§ ë‹¤ë¥´ê²Œ ì…ë ¥í•´ë„ í•´ë‹¹ ë‹¨ê³„ì— ë§ì¶”ë ¤ ì‹œë„)
    for (let k = 0; k < SCRIPT.length; k += 1) {
      if (SCRIPT[k].match(t)) {
        stepRef.current = Math.min(k + 1, SCRIPT.length - 1);
        return { text: SCRIPT[k].reply, audio: SCRIPT[k].audio };
      }
    }

    // ê·¸ë˜ë„ ì•ˆ ë§ìœ¼ë©´ í˜„ì¬ ìŠ¤í…ì˜ ë‹µì„ ê³ ì •ì ìœ¼ë¡œ ë‚´ë³´ëƒ„(ì‹œì—° ì•ˆì •ì„±)
    return { text: node.reply, audio: node.audio };
  };

  /** ============== ì „ì†¡ & ìë™ì‘ë‹µ ============== */
  const send = () => {
    const trimmed = text.trim();
    if (!trimmed) {
      return;
    }

    const myMsg: Msg = { id: newId(), text: trimmed, who: 'me' };
    setMsgs((prev) => [...prev, myMsg]);
    setText('');

    // ê³ ì • ì‹œë‚˜ë¦¬ì˜¤ë¡œ ë‹µë³€ ìƒì„±
    const { text: aiText, audio } = makeFixedReply(trimmed);

    setTimeout(() => {
      setMsgs((prev) => [...prev, { id: newId(), who: 'other', text: aiText, audioSrc: audio }]);
    }, 600);
  };

  const handleKeyDown: KeyboardEventHandler<HTMLTextAreaElement> = (e) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      send();
    }
  };

  /** ============== ë§ˆì´í¬ ì…ë ¥(ê¸°ì¡´ ìœ ì§€) ============== */
  const handleMic = () => {
    if (listening && recognitionRef.current) {
      recognitionRef.current.stop();
      setListening(false);
      return;
    }

    const Ctor: SpeechRecognitionConstructor | undefined =
      window.SpeechRecognition ?? window.webkitSpeechRecognition;

    if (!Ctor) {
      alert('ì´ ë¸Œë¼ìš°ì €ì—ì„œëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
      return;
    }

    const recog = new Ctor();
    recognitionRef.current = recog;

    recog.lang = 'ko-KR';
    recog.interimResults = true;
    recog.continuous = false;

    recog.onstart = () => {
      setListening(true);
    };
    recog.onend = () => {
      setListening(false);
    };
    recog.onerror = () => {
      setListening(false);
    };

    recog.onresult = (e: SpeechRecognitionEventLike) => {
      let transcript = '';
      for (let i = e.resultIndex; i < e.results.length; i += 1) {
        transcript += e.results[i][0].transcript;
      }
      const t = transcript.trim();
      if (t) {
        setText((prev) => (prev ? `${prev} ${t}` : t));
      }
    };

    recog.start();
  };

  /** ============== ê¸¸ê²Œ ëˆ„ë¥´ë©´ mp3 ì¬ìƒ ============== */
  const playAudio = (src?: string) => {
    if (!src) {
      return;
    }
    try {
      if (!audioRef.current) {
        audioRef.current = new Audio();
      }
      audioRef.current.pause();
      audioRef.current.src = src;
      audioRef.current.currentTime = 0;
      void audioRef.current.play().catch(() => {});
    } catch {
      // ignore
    }
  };

  const stopAudio = () => {
    if (audioRef.current) {
      audioRef.current.pause();
      audioRef.current.currentTime = 0;
    }
  };

  const handleBubbleMouseDown = (_e: MouseEvent, _text: string, audioSrc?: string) => {
    if (pressTimerRef.current) {
      window.clearTimeout(pressTimerRef.current);
    }
    pressTimerRef.current = window.setTimeout(() => {
      playAudio(audioSrc);
    }, 500);
  };

  const handleBubbleMouseUp = () => {
    if (pressTimerRef.current) {
      window.clearTimeout(pressTimerRef.current);
      pressTimerRef.current = null;
    }
    stopAudio();
  };

  return (
    <div className={s.wrap}>
      {/* ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ */}
      <div ref={listRef} className={s.list}>
        {msgs.map((m) => {
          if (m.date) {
            return (
              <div key={m.id} className={s.dateDivider}>
                <span className={s.dateChip}>{m.date}</span>
              </div>
            );
          }
          const isMe = m.who === 'me';
          return (
            <div key={m.id} className={`${s.row} ${isMe ? s.right : s.left}`}>
              <div
                className={isMe ? s.bubbleMe : s.bubbleOther}
                onMouseDown={
                  !isMe ? (e) => handleBubbleMouseDown(e, m.text, m.audioSrc) : undefined
                }
                onMouseUp={!isMe ? handleBubbleMouseUp : undefined}
                onMouseLeave={!isMe ? handleBubbleMouseUp : undefined}
                title={!isMe ? 'ê¸¸ê²Œ ëˆŒëŸ¬ ìŒì„± ë“£ê¸°' : undefined}
              >
                {m.text}
              </div>
            </div>
          );
        })}
      </div>

      {/* ì…ë ¥ ë°” */}
      <div className={s.inputBar}>
        <div className={s.inputBox}>
          <textarea
            className={s.input}
            value={text}
            placeholder="ì—¬ê¸°ì— ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
            onChange={(e) => setText(e.target.value)}
            onKeyDown={handleKeyDown}
          />

          {/* ë§ˆì´í¬ ë²„íŠ¼ */}
          <button
            className={s.micBtn}
            aria-label={listening ? 'ìŒì„± ì…ë ¥ ì¤‘ì§€' : 'ìŒì„± ì…ë ¥'}
            title={listening ? 'ìŒì„± ì…ë ¥ ì¤‘ì§€' : 'ìŒì„± ì…ë ¥'}
            onClick={handleMic}
          >
            <img
              src="/svgs/ic_mic.svg"
              alt="mic"
              className={s.micIconImg}
              style={{ opacity: listening ? 0.6 : 1 }}
            />
          </button>

          {/* ì „ì†¡ ë²„íŠ¼ */}
          <button className={s.iconBtn} aria-label="ì „ì†¡" title="ì „ì†¡" onClick={send}>
            <img src="/svgs/ic_send.svg" alt="send" className={s.iconImg} />
          </button>
        </div>
      </div>
    </div>
  );
};

export default Chat;
